{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f09f05a4ab821fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T16:08:15.804690209Z",
     "start_time": "2023-11-14T16:08:15.791297898Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.svm import SVC\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "base_folder = 'results/schaefer400'\n",
    "atlas_basename = 'schaefer400'\n",
    "output = Path('results')\n",
    "atlas_networks = [dir_ for dir_ in output.iterdir() if\n",
    "                        dir_.is_dir() and atlas_basename in dir_.name]\n",
    "output = output / atlas_basename\n",
    "subjects_df = pd.read_csv('clinical_data.csv')\n",
    "subjects_df = subjects_df.astype({'id': int})\n",
    "subjects_df = subjects_df.set_index('id')\n",
    "filename = Path('global_measures.csv')\n",
    "\n",
    "networks_names = {\n",
    "      \"SalVentAttnLH\": \"Salience/Ventral Attention (Left Hemisphere)\", \"SalVentAttn\": \"Salience/Ventral Attention\",\n",
    "      \"DorsAttn\": \"Dorsal Attention\", \"Cont\": \"Frontoparietal\", \"SomMot\": \"Somatomotor\", \"Default\": \"Default\", \"Vis\": \"Visual\",\n",
    "      \"Limbic\": \"Limbic\", \"Global\": \"Global\"\n",
    "    }\n",
    "networks_nce = {\n",
    "      \"SalVentAttnLH\": \"language\", \"SalVentAttn\": \"executive\", \"DorsAttn\": \"attention\", \"SomMot\": \"executive\",\n",
    "      \"Cont\": \"visuoespatial\", \"Default\": \"memory\", \"Vis\": \"visuoespatial\", \"Limbic\": \"memory\", \"Global\": \"attention\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "75dd7207148efa89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T16:08:18.076839081Z",
     "start_time": "2023-11-14T16:08:18.074258782Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_curve(graph_densities, measure, lower_error, upper_error, group, color_index, ax):\n",
    "    ax.plot(graph_densities, measure, label=group, color=f'C{color_index}')\n",
    "    ax.plot(graph_densities, lower_error, alpha=0.1, color=f'C{color_index}')\n",
    "    ax.plot(graph_densities, upper_error, alpha=0.1, color=f'C{color_index}')\n",
    "    ax.legend()\n",
    "    ax.fill_between(graph_densities, lower_error, upper_error, alpha=0.2)\n",
    "\n",
    "    \n",
    "def add_statistical_significance(p_at_thresholds, ax, significance_levels, eps=1e-4):\n",
    "    pvalues = p_at_thresholds[p_at_thresholds.columns[0]]\n",
    "    labels = ['*' * i for i in range(len(significance_levels), 0, -1)]\n",
    "    significance_levels.insert(0, 0.0)\n",
    "    significance_levels.append(1.)\n",
    "    labels.append('ns')\n",
    "    categorized_pvalues = pd.cut(pvalues, significance_levels, right=False, labels=labels)\n",
    "    spacing = 0.1\n",
    "    if len(pvalues) > 1:\n",
    "        spacing = pvalues.index[1] - pvalues.index[0] + eps\n",
    "\n",
    "    significance_bar(ax, categorized_pvalues, labels, spacing)\n",
    "    \n",
    "    \n",
    "def significance_bar(ax, categorized_pvalues, labels, spacing):\n",
    "    line_y = ax.get_ylim()[1]\n",
    "    max_threshold, min_threshold = categorized_pvalues.index[-1], categorized_pvalues.index[0]\n",
    "    # Use light grey for *, dark grey for **, and black for ***\n",
    "    colors = {label: col for label, col in zip(labels, colormaps.get_cmap('Greys')(np.linspace(0.8, 0.2, len(labels))))}\n",
    "    for label in labels:\n",
    "        significant_values = categorized_pvalues[categorized_pvalues == label]\n",
    "        # Build a list of tuples with the start and end of each significant region\n",
    "        if len(significant_values) > 0 and label not in 'ns':\n",
    "            significant_regions = [(significant_values.index[0], significant_values.index[0])]\n",
    "            for i, threshold in enumerate(significant_values.index):\n",
    "                if i > 0:\n",
    "                    if threshold - significant_values.index[i - 1] > spacing:\n",
    "                        significant_regions.append((threshold, threshold))\n",
    "                    else:\n",
    "                        significant_regions[-1] = (significant_regions[-1][0], threshold)\n",
    "            \n",
    "            significant_regions = [(start - spacing, end + spacing) for start, end in significant_regions]\n",
    "            for start, end in significant_regions:\n",
    "                if end > max_threshold:\n",
    "                    end = max_threshold\n",
    "                if start < min_threshold:\n",
    "                    start = min_threshold\n",
    "                ax.plot((start, end), [line_y * 0.98, line_y * 0.98], linewidth=2, color=colors[label])\n",
    "\n",
    "def get_network_name(atlas_basename, network):\n",
    "    return network.lstrip(f'{atlas_basename}_') if is_network(network) else 'Global'\n",
    "\n",
    "\n",
    "def is_network(atlas_name):\n",
    "    return len(atlas_name.split('_')) > 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3247a3a2aee5de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T16:13:43.657857365Z",
     "start_time": "2023-11-14T16:13:43.538461874Z"
    }
   },
   "outputs": [],
   "source": [
    "def meshgrid(x, y, h=.02, offset=0.07):\n",
    "    x_min, x_max = x.min() - offset, x.max() + offset\n",
    "    y_min, y_max = y.min() - offset, y.max() + offset\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def add_svm_contours(ax, clf, xx, yy, **params):\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    return ax.contourf(xx, yy, Z, **params)\n",
    "\n",
    "\n",
    "def normalize_values(df, columns):\n",
    "    df[columns] = df[columns].astype(float)\n",
    "    for column in columns:\n",
    "        df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_measure_at_threshold(subjects_df, groups, measure_label, network, network_nce, filename):\n",
    "    graph_density, nces, values, categories, group_mapping = 0.0, [], [], [], {}\n",
    "    for j, group in enumerate(groups):\n",
    "        group_df = subjects_df[subjects_df['group'] == group]\n",
    "        group_mapping[group] = j\n",
    "        group_network_measures = pd.read_pickle(network / f'{filename.stem}_{group}.pkl')\n",
    "        measures_at_threshold = group_network_measures.sort_values(by='threshold').iloc[-1]\n",
    "        if measure_label not in measures_at_threshold.index:\n",
    "            continue\n",
    "        graph_density = measures_at_threshold['threshold']\n",
    "        nces.extend(group_df[network_nce].values)\n",
    "        values.extend(measures_at_threshold[measure_label])\n",
    "        categories.extend([group] * len(group_df))\n",
    "    df = pd.DataFrame({'nce': nces, 'measure': values, 'group': categories}).dropna()\n",
    "    df = normalize_values(df, ['nce', 'measure'])\n",
    "    return graph_density, df, group_mapping\n",
    "\n",
    "\n",
    "def fit_and_plot_svm(df, cats_mapping, ax):\n",
    "    df = df.replace({'group': cats_mapping})\n",
    "    clf_nces, clf = SVC(), SVC()\n",
    "    features = df[['nce', 'measure']].values\n",
    "    nces = features[:, 0].reshape(-1, 1)\n",
    "    categories = df['group'].values\n",
    "    # Do a LOOCV to get the accuracy\n",
    "    accuracies_nce, accuracies_features = [], []\n",
    "    for i in range(len(features)):\n",
    "        clf_nces.fit(np.delete(nces, i, axis=0), np.delete(categories, i))\n",
    "        accuracies_nce.append(clf_nces.score(nces[i].reshape(1, -1), categories[i].reshape(1, -1)))\n",
    "        clf.fit(np.delete(features, i, axis=0), np.delete(categories, i))\n",
    "        accuracies_features.append(clf.score(features[i].reshape(1, -1), categories[i].reshape(1, -1)))\n",
    "    nce_mean, nce_std = np.mean(accuracies_nce), np.std(accuracies_nce)\n",
    "    features_mean, features_std = np.mean(accuracies_features), np.std(accuracies_features)\n",
    "    print(f'Mean NCE accuracy: {nce_mean} +/- {nce_std}')\n",
    "    print(f'Mean features accuracy: {features_mean} +/- {features_std}')\n",
    "    clf.fit(features, categories)\n",
    "    xx, yy = meshgrid(features[:, 0], features[:, 1])\n",
    "    add_svm_contours(ax, clf, xx, yy, cmap='coolwarm', alpha=0.1)\n",
    "    \n",
    "    return features_mean - nce_mean, np.sqrt(nce_std ** 2 + features_std ** 2)\n",
    "    \n",
    "\n",
    "\n",
    "def add_group_to_plot(measures_values, group, color_index, measure_label, ax):\n",
    "    group_values = measures_values[measures_values['group'] == group]\n",
    "    densities, auc_value = group_values['threshold'].values, 0.0\n",
    "    if measure_label in group_values.columns:\n",
    "        measure_values = group_values[measure_label].values\n",
    "        lower_error, upper_error = group_values[measure_label] - group_values[f'{measure_label}_ste'], \\\n",
    "                                   group_values[measure_label] + group_values[f'{measure_label}_ste']\n",
    "        sorted_densities = np.argsort(densities)\n",
    "        if group == 'covid':\n",
    "            group = 'long-COVID'\n",
    "        else:\n",
    "            group = group.capitalize()\n",
    "        add_curve(densities, measure_values, lower_error, upper_error, group, color_index, ax)\n",
    "        if len(densities) > 1:\n",
    "            auc_value = auc(densities[sorted_densities], measure_values[sorted_densities])\n",
    "    return auc_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8ad0f42cbbceceb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T16:13:25.623511507Z",
     "start_time": "2023-11-14T16:13:25.488419139Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_nce_to_measure(atlas_basename, networks_dirs, networks_names, subjects_df, measure_label, measure_desc,\n",
    "                        networks_nce, output, filename):\n",
    "    ncols, nrows = 2, -(-len(networks_dirs) // 2)\n",
    "    fig, axes = plt.subplots(figsize=(15, 5 * nrows), nrows=nrows, ncols=ncols)\n",
    "    gains = {network.name: {} for network in networks_dirs}\n",
    "    for i, network in enumerate(networks_dirs):\n",
    "        print(f'Processing {network.name}')\n",
    "        ax = axes[i // 2, i % 2] if nrows > 1 else axes[i % 2]\n",
    "        network_basename = get_network_name(atlas_basename, network.name)\n",
    "        if network_basename not in networks_nce:\n",
    "            continue\n",
    "        network_nce = networks_nce[network_basename]\n",
    "        groups = sorted(subjects_df['group'].unique())\n",
    "        connection_density, measure_df, group_mapping = get_measure_at_threshold(subjects_df, groups, measure_label, network,\n",
    "                                                                            network_nce, filename)\n",
    "        plot_df = measure_df.copy().replace({'group': {'covid': 'long-COVID', 'control': 'Control'}})\n",
    "        sns.scatterplot(data=plot_df, x='nce', y='measure', hue='group', ax=ax)\n",
    "        if not measure_df.empty:\n",
    "            gains[network.name] = fit_and_plot_svm(measure_df, group_mapping, ax)\n",
    "        ax.legend()\n",
    "        ax.set_title(f'{networks_names[network_basename]}')\n",
    "        ax.set_ylabel(f'{measure_desc} at t={connection_density * 100:.0f}%')\n",
    "        ax.set_xlabel(f'{network_nce} score')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "    fig.suptitle(measure_desc)\n",
    "    fig.savefig(output / f'NCE_to_{measure_label}.png')\n",
    "    plt.show()\n",
    "\n",
    "    return gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3233a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_efficiency(atlas_basename, networks_dirs, subjects_df,\n",
    "                        networks_nce, filename):\n",
    "    gains = {network.name: {} for network in networks_dirs}\n",
    "    for network in networks_dirs:\n",
    "        print(f'Processing {network.name}')\n",
    "        network_basename = get_network_name(atlas_basename, network.name)\n",
    "        if network_basename not in networks_nce:\n",
    "            continue\n",
    "        network_nce = networks_nce[network_basename]\n",
    "        groups = sorted(subjects_df['group'].unique())\n",
    "        measure_df, group_mapping = get_efficiency_at_threshold(subjects_df, groups, network,\n",
    "                                                                            network_nce, filename)\n",
    "        if not measure_df.empty:\n",
    "            gains[network.name] = fit_svm(measure_df, group_mapping)\n",
    "        \n",
    "\n",
    "    return gains\n",
    "\n",
    "\n",
    "def fit_svm(df, cats_mapping):\n",
    "    df = df.replace({'group': cats_mapping})\n",
    "    clf_nces, clf = SVC(), SVC()\n",
    "    features = df[['nce', 'local_eff', 'global_eff']].values\n",
    "    nces = features[:, 0].reshape(-1, 1)\n",
    "    categories = df['group'].values\n",
    "    accuracies_nce, accuracies_features = [], []\n",
    "    for i in range(len(features)):\n",
    "        clf_nces.fit(np.delete(nces, i, axis=0), np.delete(categories, i))\n",
    "        accuracies_nce.append(clf_nces.score(nces[i].reshape(1, -1), categories[i].reshape(1, -1)))\n",
    "        clf.fit(np.delete(features, i, axis=0), np.delete(categories, i))\n",
    "        accuracies_features.append(clf.score(features[i].reshape(1, -1), categories[i].reshape(1, -1)))\n",
    "    nce_mean, nce_std = np.mean(accuracies_nce), np.std(accuracies_nce)\n",
    "    features_mean, features_std = np.mean(accuracies_features), np.std(accuracies_features)\n",
    "    print(f'Mean NCE accuracy: {nce_mean} +/- {nce_std}')\n",
    "    print(f'Mean features accuracy: {features_mean} +/- {features_std}')\n",
    "    \n",
    "    return features_mean - nce_mean, np.sqrt(nce_std ** 2 + features_std ** 2)\n",
    "\n",
    "def get_efficiency_at_threshold(subjects_df, groups, network, network_nce, filename):\n",
    "    nces, local_eff_values, global_eff_values, categories, group_mapping = [], [], [], [], {}\n",
    "    for j, group in enumerate(groups):\n",
    "        group_df = subjects_df[subjects_df['group'] == group]\n",
    "        group_mapping[group] = j\n",
    "        group_network_measures = pd.read_pickle(network / f'{filename.stem}_{group}.pkl')\n",
    "        measures_at_threshold = group_network_measures.sort_values(by='threshold').iloc[-1]\n",
    "        if 'global_efficiency' not in measures_at_threshold.index or 'avg_local_efficiency' not in measures_at_threshold.index:\n",
    "            continue\n",
    "        graph_density = measures_at_threshold['threshold']\n",
    "        nces.extend(group_df[network_nce].values)\n",
    "        local_eff_values.extend(measures_at_threshold['avg_local_efficiency'])\n",
    "        global_eff_values.extend(measures_at_threshold['global_efficiency'])\n",
    "        categories.extend([group] * len(group_df))\n",
    "    df = pd.DataFrame({'nce': nces, 'local_eff': local_eff_values, 'global_eff': global_eff_values, 'group': categories}).dropna()\n",
    "    df = normalize_values(df, ['nce', 'local_eff', 'global_eff'])\n",
    "    \n",
    "    return df, group_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc8fcd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_with_efficiency(atlas_basename, atlas_networks, subjects_df, networks_nce, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74c0bb7b5d0b9c8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T16:14:01.618829784Z",
     "start_time": "2023-11-14T16:13:58.529480517Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_nce_to_measure(atlas_basename, atlas_networks, networks_names, subjects_df, 'global_efficiency', 'Global Efficiency', networks_nce, output, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc2cc19db975d1ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T16:10:09.843009355Z",
     "start_time": "2023-11-14T16:10:06.585822430Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_nce_to_measure(atlas_basename, atlas_networks, networks_names, subjects_df, 'avg_local_efficiency', 'Avg. Local Efficiency', networks_nce, output, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e5b2995ea22e0e00",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_measure(atlas_basename, networks_dirs, networks_names, measure_label, measure_desc, output, filename):\n",
    "    ncols, nrows = 2, -(-len(networks_dirs) // 2)\n",
    "    fig, axes = plt.subplots(figsize=(15, 5 * nrows), nrows=nrows, ncols=ncols)\n",
    "    aucs = {network.name: {} for network in networks_dirs}\n",
    "    for i, network in enumerate(networks_dirs):\n",
    "        measures_values = pd.read_csv(network / filename.name, index_col=0)\n",
    "        ax = axes[i // 2, i % 2] if nrows > 1 else axes[i % 2]\n",
    "        groups = sorted(measures_values['group'].unique())\n",
    "        for color_index, group in enumerate(groups):\n",
    "            aucs[network.name][group] = add_group_to_plot(measures_values, group, color_index, measure_label, ax)\n",
    "        if f'{measure_label}_p' in measures_values.columns:\n",
    "            p_at_thresholds = measures_values[['threshold', f'{measure_label}_p']].drop_duplicates().set_index(\n",
    "                'threshold')\n",
    "            add_statistical_significance(p_at_thresholds, ax, significance_levels=[0.001, 0.005, 0.01])\n",
    "        network_basename = get_network_name(atlas_basename, network.name)\n",
    "        ax.set_title(f'{networks_names[network_basename]}')\n",
    "        ax.set_xlabel('Connection density (%)', fontsize=12)\n",
    "        ax.set_ylabel(measure_desc, fontsize=12)\n",
    "        ax.spines['top'].set_visible(False), ax.spines['right'].set_visible(False)\n",
    "        ax.set_xticks(ax.get_xticks()[1:-1])\n",
    "        ax.set_yticks(ax.get_yticks()[1:-1])\n",
    "        ax.set_yticklabels([f'{tick:.2f}' for tick in ax.get_yticks()])\n",
    "        ax.set_xticklabels([f'{tick * 100:.0f}' for tick in ax.get_xticks()])\n",
    "    fig.suptitle(measure_desc)\n",
    "    fig.savefig(output / f'{measure_label}.png')\n",
    "    plt.show()\n",
    "\n",
    "    return aucs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "afd5642300c9fc91",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_measure(atlas_basename, atlas_networks, networks_names, 'avg_clustering', 'Avg. Clustering Coefficient', output, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eb1ab6d785a9d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_measure(atlas_basename, atlas_networks, networks_names, 'avg_local_efficiency', 'Avg. Local efficiency', output, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
